{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f77d583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "from google.oauth2.service_account import Credentials\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox, filedialog, ttk\n",
    "from tkinter import font as tkfont\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4651363a",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f7c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8415b888",
   "metadata": {},
   "source": [
    "## GoogelSheet Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25cbe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = \"C:\\\\Users\\\\Yahya Negm\\\\Downloads\\\\scraping-googel.json\"\n",
    "scope = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
    "creds = Credentials.from_service_account_file(json_path, scopes=scope)\n",
    "client = gspread.authorize(creds)\n",
    "spreadsheet_id = \"1m34SuaD_LMjfsEpn8wjwuAyYVHfy7C0jM3BM1Gg24Mk\"\n",
    "sheet = client.open_by_key(spreadsheet_id).worksheet(\"Facebook\")\n",
    "\n",
    "data = sheet.get_all_records()\n",
    "credentials = {entry[\"Username\"]: str(entry[\"Password\"]) for entry in data}\n",
    "\n",
    "url_list = [{\"Url\": row[\"Url\"], \"Name\": row[\"Name\"]} for row in data if \"Url\" in row and \"Name\" in row]\n",
    "url_display_values = [f\"{item['Name']} - {item['Url']}\" for item in url_list]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70927cc",
   "metadata": {},
   "source": [
    "## Check log-in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766a3de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_login():\n",
    "    username = username_entry.get()\n",
    "    password = password_entry.get()\n",
    "    if username in credentials and credentials[username] == password:\n",
    "        messagebox.showinfo(\"Login Success\", \"Welcome!\")\n",
    "        login_frame.pack_forget()\n",
    "        open_scraper_window()\n",
    "        \n",
    "        # Change geometry after successful login\n",
    "        window_width = 700\n",
    "        window_height = 800\n",
    "        screen_width = root.winfo_screenwidth()\n",
    "        screen_height = root.winfo_screenheight()\n",
    "\n",
    "        # Calculate the position to center the window\n",
    "        x = (screen_width // 2) - (window_width // 2)\n",
    "        y = (screen_height // 2) - (window_height // 2)\n",
    "\n",
    "        # Set the initial window position and size\n",
    "        root.geometry(f\"{window_width}x{window_height}+{x}+{y}\")\n",
    "        root.resizable(False, False)  # Lock the window size to prevent resizing\n",
    "\n",
    "    else:\n",
    "        messagebox.showerror(\"Login Failed\", \"Invalid Username or Password\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5ac083",
   "metadata": {},
   "source": [
    "## extract text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c726ba76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(element, xpath, default_value):\n",
    "    try:\n",
    "        return WebDriverWait(element, 5).until(EC.presence_of_element_located((By.XPATH, xpath))).text.strip()\n",
    "    except TimeoutException:\n",
    "        return default_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165cf5c1",
   "metadata": {},
   "source": [
    "## extract link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6663a0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_link(element, xpath, default_value):\n",
    "    try:\n",
    "        link = WebDriverWait(element, 5).until(EC.presence_of_element_located((By.XPATH, xpath))).get_attribute('href')\n",
    "        return link.split(\"?\")[0]\n",
    "    except TimeoutException:\n",
    "        return default_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2217bb",
   "metadata": {},
   "source": [
    "## extract photo_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b90245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_photo_links(element, xpath):\n",
    "    try:\n",
    "        return [photo.get_attribute(\"src\") for photo in WebDriverWait(element, 5).until(EC.presence_of_all_elements_located((By.XPATH, xpath)))]\n",
    "    except TimeoutException:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35623bf7",
   "metadata": {},
   "source": [
    "## Scrap Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2dc2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_post_text(driver, num_posts, file_path, url, group_name):\n",
    "    # Initialize an empty DataFrame to store scraped data\n",
    "    df = pd.DataFrame(columns=[\"group_name\", \"poster_name\", \"text\", \"post_link\", \"profile_link\", \"photo_links\"])\n",
    "    collected_posts = 0\n",
    "    driver.execute_script(\"document.body.style.zoom='30%'\")\n",
    "    \n",
    "\n",
    "    # File path for output Excel file\n",
    "    output_filename = os.path.join(file_path, \"Facebook_Data.xlsx\")\n",
    "\n",
    "    # Load existing data if the file exists\n",
    "    if os.path.exists(output_filename):\n",
    "        existing_df = pd.read_excel(output_filename, engine='openpyxl')\n",
    "    else:\n",
    "        existing_df = pd.DataFrame(columns=[\"group_name\", \"poster_name\", \"text\", \"post_link\", \"profile_link\", \"photo_links\"])\n",
    "\n",
    "    while collected_posts < num_posts:\n",
    "        posts = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, '//div[contains(@class, \"x1yztbdb x1n2onr6 xh8yej3 x1ja2u2z\")]'))\n",
    "        )\n",
    "        for post in posts:\n",
    "            if collected_posts >= num_posts:\n",
    "                break\n",
    "            try:\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView(true);\", post)\n",
    "                time.sleep(1)\n",
    "                poster_name = extract_text(post, './/span[contains(@class, \"xdj266r x11i5rnm xat24cr x1mh8g0r xexx8yu x4uap5 x18d9i69 xkhd6sd x1hl2dhg x16tdsg8 x1vvkbs\")]', \"Name not found\")\n",
    "                post_text = extract_text(post, './/div[contains(@class, \"xdj266r x11i5rnm xat24cr x1mh8g0r x1vvkbs x126k92a\")]', \"No text found in specified class.\")\n",
    "                profile_link = extract_link(post, './/a[contains(@href, \"/profile.php\") or contains(@href, \"/groups/\")]', \"Profile link not found\")\n",
    "                post_link = extract_link(post, './/a[contains(@href, \"/posts/\")]', \"Post link not found\")\n",
    "                photo_links = extract_photo_links(post, './/img[contains(@class, \"xz74otr x1ey2m1c xds687c x5yr21d x10l6tqk x17qophe x13vifvy xh8yej3\")]')\n",
    "\n",
    "                # Check for duplicates in the combined data (existing + current)\n",
    "                combined_df = pd.concat([existing_df, df], ignore_index=True)\n",
    "                is_duplicate = not combined_df[(combined_df[\"poster_name\"] == poster_name) & (combined_df[\"text\"] == post_text)].empty\n",
    "                Extract_Time_D = datetime.now().strftime('%d-%m-%Y %p')\n",
    "                Extract_Time_T = datetime.now().strftime('%H:%M:%S')\n",
    "\n",
    "                if not is_duplicate and post_text != \"No text found in specified class.\" and post_text:\n",
    "                    # Add the new post to the DataFrame\n",
    "                    new_row = pd.DataFrame([{\n",
    "                        \"group_name\": group_name,\n",
    "                        \"poster_name\": poster_name,\n",
    "                        \"text\": post_text,\n",
    "                        \"post_link\": post_link,\n",
    "                        \"profile_link\": profile_link,\n",
    "                        \"photo_links\": \", \".join(photo_links),\n",
    "                        \"Extract-Day\": Extract_Time_D,\n",
    "                        \"Extract-Time\": Extract_Time_T\n",
    "                    }])\n",
    "                    df = pd.concat([df, new_row], ignore_index=True)\n",
    "                    collected_posts += 1\n",
    "                    log_message(f\"Scraped post from: {poster_name}\")\n",
    "                else:\n",
    "                    pass\n",
    "            except Exception as e:\n",
    "                log_message(f\"Error processing post: {e}\")\n",
    "        driver.execute_script(\"window.scrollBy(0, 800);\")\n",
    "        posts = driver.find_elements(By.XPATH, '//div[contains(@class, \"x1yztbdb x1n2onr6 xh8yej3 x1ja2u2z\")]')\n",
    "        if posts:\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", posts[-1])  # Scroll to the last post####\n",
    "             \n",
    "    # Combine new data with existing data\n",
    "    final_df = pd.concat([existing_df, df], ignore_index=True)\n",
    "    final_df.to_excel(output_filename, index=False, engine='openpyxl')\n",
    "    log_message(f\"Data saved to {output_filename}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b270b752",
   "metadata": {},
   "source": [
    "## Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3719a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_message(message):\n",
    "    log_text.insert(tk.END, message + '\\n')\n",
    "    log_text.see(tk.END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fc3539",
   "metadata": {},
   "source": [
    "## start Button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1123fb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_scraping():\n",
    "    global driver\n",
    "    selected_indices = url_listbox.curselection()\n",
    "    \n",
    "    if not selected_indices:\n",
    "        log_message(\"Please select at least one URL.\")\n",
    "        return\n",
    "\n",
    "    num_posts = num_posts_entry.get()\n",
    "    file_path = file_path_entry.get()\n",
    "\n",
    "    if not num_posts.isdigit() or not file_path:\n",
    "        log_message(\"Please enter the number of posts and file path.\")\n",
    "        return\n",
    "\n",
    "    num_posts = int(num_posts)\n",
    "    \n",
    "    # Initialize the driver\n",
    "    try:\n",
    "        user_data_dir = os.path.join(os.path.expanduser('~'), 'User_Data')\n",
    "        options = webdriver.ChromeOptions()\n",
    "        service = Service()\n",
    "        os.makedirs(user_data_dir, exist_ok=True)\n",
    "        options.add_argument(f\"user-data-dir={user_data_dir}\")\n",
    "        driver = webdriver.Chrome(service=service, options=options)\n",
    "        driver.maximize_window()\n",
    "    except Exception as e:\n",
    "        log_message(f\"Failed to initialize WebDriver: {e}\")\n",
    "        return\n",
    "\n",
    "    # Main scraping loop\n",
    "    try:\n",
    "        for index in selected_indices:\n",
    "            selected_url = url_list[index][\"Url\"]\n",
    "            group_name = url_list[index][\"Name\"]  # Group name as a column\n",
    "            \n",
    "            try:\n",
    "                driver.get(selected_url)\n",
    "                log_message(f\"Starting extraction for: {selected_url} (Group: {group_name})\")\n",
    "                df = scrape_post_text(driver, num_posts=num_posts, file_path=file_path, url=selected_url,group_name=group_name)\n",
    "                log_message(f\"Extraction completed for {selected_url} (Group: {group_name}).\")\n",
    "            except Exception as e:\n",
    "                log_message(f\"An error occurred on {selected_url} (Group: {group_name}): {e}\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error during scraping loop: {e}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "        log_message(\"Scraping completed for all selected URLs.\")\n",
    "\n",
    "\n",
    "def start_scraping_thread():\n",
    "    thread = threading.Thread(target=start_scraping)\n",
    "    thread.start()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1575bd51",
   "metadata": {},
   "source": [
    "## stop Button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b206453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_scraping():\n",
    "    global driver\n",
    "    if driver:\n",
    "        driver.quit()\n",
    "        driver = None\n",
    "        log_message(\"Scraping has been stopped and browser closed.\")\n",
    "    else:\n",
    "        log_message(\"Scraping not in progress.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06cf5ec",
   "metadata": {},
   "source": [
    "## Broswer Button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d301af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def browse_path():\n",
    "    selected_path = filedialog.askdirectory()\n",
    "    if selected_path:\n",
    "        file_path_entry.delete(0, tk.END)\n",
    "        file_path_entry.insert(0, selected_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10725edd",
   "metadata": {},
   "source": [
    "## Open Facebook Button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422303d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_facebook_login():\n",
    "    global driver\n",
    "    if driver is None:\n",
    "        user_data_dir = os.path.join(os.path.expanduser('~'), 'User_Data')\n",
    "        options = webdriver.ChromeOptions()\n",
    "        service = Service()\n",
    "        os.makedirs(user_data_dir, exist_ok=True)\n",
    "        options.add_argument(f\"user-data-dir={user_data_dir}\")\n",
    "        driver = webdriver.Chrome(service=service, options=options)\n",
    "        driver.maximize_window()  \n",
    "    driver.get(\"https://www.facebook.com/login\")\n",
    "    log_message(\"Opened Facebook login page. Please log in.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771ccbc7-f8ae-4998-81ec-52bf6a1d25c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1559cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rounded_frame(parent, text):\n",
    "    frame = tk.Frame(parent, bg=\"#ffffff\", highlightthickness=2, highlightbackground=\"#e2e8f0\", padx=10, pady=10)\n",
    "    label = tk.Label(frame, text=text, font=(\"Helvetica\", 10), bg=\"#ffffff\", fg=\"#4a5568\")\n",
    "    label.pack(anchor=\"w\", padx=10)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d625920-cf38-4d63-95a9-dccb3621e486",
   "metadata": {},
   "source": [
    "## Frame design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e467daee-d698-4648-8463-66b190bad8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rounded_frame(parent, text):\n",
    "    frame = tk.Frame(parent, bg=\"#ffffff\", highlightthickness=2, highlightbackground=\"#e2e8f0\", padx=10, pady=10)\n",
    "    label = tk.Label(frame, text=text, font=(\"Helvetica\", 10), bg=\"#ffffff\", fg=\"#4a5568\")\n",
    "    label.pack(anchor=\"w\", padx=10)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3061c078",
   "metadata": {},
   "source": [
    "## Funcation switch to Scrap GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d91237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_scraper_window():\n",
    "    scraper_frame.pack(fill=\"both\", expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5506aaa7",
   "metadata": {},
   "source": [
    "## GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd6bb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = tk.Tk()\n",
    "root.title(\"SBS Tool \")\n",
    "##root.iconbitmap(\"C:\\\\Users\\\\Khaled\\\\Desktop\\\\sbs_logo.ico\")\n",
    "root.configure(bg=\"#f8f9fa\")\n",
    "\n",
    "\n",
    "window_width = 700\n",
    "window_height = 270\n",
    "screen_width = root.winfo_screenwidth()\n",
    "screen_height = root.winfo_screenheight()\n",
    "x = (screen_width // 2) - (window_width // 2)\n",
    "y = (screen_height // 2) - (window_height // 2)\n",
    "root.geometry(f\"{window_width}x{window_height}+{x}+{y}\")\n",
    "root.resizable(False, False) \n",
    "\n",
    "\n",
    "# Header\n",
    "header = tk.Label(root, text=\"SBS Facebook Data \", font=(\"Helvetica\", 15, \"bold\"), bg=\"#f8f9fa\", fg=\"#3b82f6\")\n",
    "header.pack(pady=20)\n",
    "\n",
    "# Login Frame\n",
    "login_frame = create_rounded_frame(root, \"Login\")\n",
    "login_frame.pack(padx=20, pady=10, fill=\"x\")\n",
    "\n",
    "username_entry = ttk.Entry(login_frame, width=40)\n",
    "username_entry.pack(pady=5, ipady=4)\n",
    "password_entry = ttk.Entry(login_frame, show=\"*\", width=40)\n",
    "password_entry.pack(pady=5, ipady=4)\n",
    "login_button = tk.Button(login_frame, text=\"Login\", command=verify_login, bg=\"#3b82f6\", fg=\"white\", font=(\"Helvetica\", 10, \"bold\"), padx=20)\n",
    "login_button.pack(pady=10)\n",
    "\n",
    "# Scraper Frame\n",
    "scraper_frame = create_rounded_frame(root, \"Scraper Settings\")\n",
    "scraper_frame.pack(padx=20, pady=10, fill=\"x\")\n",
    "\n",
    "# URL Listbox\n",
    "url_label = tk.Label(scraper_frame, text=\"Select Facebook Group URLs:\", font=(\"Helvetica\", 10), bg=\"#ffffff\", fg=\"#4a5568\")\n",
    "url_label.pack(anchor=\"w\", padx=10)\n",
    "url_listbox = tk.Listbox(scraper_frame, selectmode=tk.MULTIPLE, width=50, height=10, bg=\"#f1faee\", bd=1, relief=\"flat\")\n",
    "url_listbox.pack(padx=10, pady=5)\n",
    "\n",
    "for item in url_display_values:\n",
    "    url_listbox.insert(tk.END, item)\n",
    "\n",
    "num_posts_frame = tk.Frame(scraper_frame, bg=\"#ffffff\")\n",
    "num_posts_frame.pack(anchor=\"w\", padx=12, pady=5, fill=\"x\")\n",
    "\n",
    "# Label inside the frame\n",
    "num_posts_label = tk.Label(num_posts_frame, text=\"Enter number of posts per URL:\", font=(\"Helvetica\", 10), bg=\"#ffffff\", fg=\"#4a5568\")\n",
    "num_posts_label.pack(side=\"left\")\n",
    "\n",
    "# Entry inside the same frame\n",
    "num_posts_entry = ttk.Entry(num_posts_frame, width=40)\n",
    "num_posts_entry.pack(side=\"left\", padx=10, ipady=4)\n",
    "\n",
    "file_path_frame = tk.Frame(scraper_frame, bg=\"#ffffff\")\n",
    "file_path_frame.pack(anchor=\"w\", padx=12, pady=5, fill=\"x\")\n",
    "\n",
    "# Label for file path inside the frame\n",
    "file_path_label = tk.Label(file_path_frame, text=\"Enter file path to save data:\", font=(\"Helvetica\", 10), bg=\"#ffffff\", fg=\"#4a5568\")\n",
    "file_path_label.pack(side=\"left\")\n",
    "\n",
    "# Entry for file path inside the same frame\n",
    "file_path_entry = ttk.Entry(file_path_frame, width=40)\n",
    "file_path_entry.pack(side=\"left\", padx=35, ipady=4)\n",
    "\n",
    "# Browse button inside the same frame\n",
    "browse_button = tk.Button(file_path_frame, text=\"Browse\", command=browse_path, bg=\"#3b82f6\", fg=\"white\", font=(\"Helvetica\", 10, \"bold\"))\n",
    "browse_button.pack(side=\"left\", padx=10)\n",
    "\n",
    "# Control Buttons\n",
    "login_facebook_button = tk.Button(scraper_frame, text=\"Log In to Facebook\", command=open_facebook_login, bg=\"#3b82f6\", fg=\"white\", font=(\"Helvetica\", 10, \"bold\"), padx=20)\n",
    "login_facebook_button.pack(pady=5)\n",
    "\n",
    "start_button = tk.Button(scraper_frame, text=\"Start Scraping\", command=start_scraping_thread, bg=\"#2a9d8f\", fg=\"white\", font=(\"Helvetica\", 10, \"bold\"), padx=20)\n",
    "start_button.pack(pady=10)\n",
    "\n",
    "stop_button = tk.Button(scraper_frame, text=\"Stop Scraping\", command=stop_scraping, bg=\"#e63946\", fg=\"white\", font=(\"Helvetica\", 10, \"bold\"), padx=20)\n",
    "stop_button.pack(pady=5)\n",
    "\n",
    "# Log display\n",
    "log_frame = create_rounded_frame(root, \"Logs\")\n",
    "log_frame.pack(padx=20, pady=10, fill=\"x\")\n",
    "log_text = tk.Text(log_frame, wrap=\"word\", height=10, width=60, bg=\"#f1faee\", font=(\"Helvetica\", 9), bd=0, relief=\"flat\")\n",
    "log_text.pack(pady=10)\n",
    "log_text.insert(tk.END, \"Logs:\\n\")\n",
    "\n",
    "scraper_frame.pack_forget()  # Hide the scraper frame initially\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e3aee9",
   "metadata": {},
   "source": [
    "## Run GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9aeb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
